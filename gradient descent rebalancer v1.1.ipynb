{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pdb\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Error spot\n",
    "# somehow not able to install Tensorflow...\n",
    "# How to set python3 in Jupyter Notebook? \n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/envs/grad/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "TSLAdata=pd.read_csv(\"TSLA_2020_2020.txt\",delimiter=\"\\,\")\n",
    "TSLAdata.columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "#TSLAdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_DEBUGGING = False\n",
    "DEBUGGING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/envs/grad/lib/python3.7/site-packages/ipykernel_launcher.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL\n",
    "\n",
    "tickers = [\"TSLA\"]\n",
    "mins_ago_to_fetch = 100000  # see also filter_history_by_date()\n",
    "ticker_history = {}\n",
    "hist_length = 0\n",
    "average_returns = {}\n",
    "cumulative_returns = {}\n",
    "\n",
    "def fetch_all():\n",
    "  for ticker in tickers:\n",
    "    ticker_history[ticker] = fetch_history(ticker)\n",
    "\n",
    "def fetch_history(ticker):\n",
    "  hist = pd.read_csv(\"TSLA_2020_2020.txt\",delimiter=\"\\,\")\n",
    "  hist.columns = [\"timestamp\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "  #hist = TSLAdata\n",
    "  hist = index_history(hist)\n",
    "  hist = filter_history_by_date(hist)\n",
    "  return hist\n",
    "\n",
    "def index_history(hist):\n",
    "  # index by date so we can easily filter by a given timeframe\n",
    "  hist = hist.set_index('timestamp')\n",
    "  hist.index = pd.to_datetime(hist.index, unit='ns')\n",
    "  return hist\n",
    "\n",
    "def filter_history_by_date(hist):\n",
    "  result = hist[hist.index.year >= 2016]\n",
    "  # result = result[result.index.day == 1] # every first of month, etc.\n",
    "  return result\n",
    "\n",
    "fetch_all()\n",
    "hist_length = len(ticker_history[tickers[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:03:00</th>\n",
       "      <td>422.07</td>\n",
       "      <td>422.50</td>\n",
       "      <td>422.07</td>\n",
       "      <td>422.50</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:04:00</th>\n",
       "      <td>422.16</td>\n",
       "      <td>422.16</td>\n",
       "      <td>422.16</td>\n",
       "      <td>422.16</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:07:00</th>\n",
       "      <td>423.00</td>\n",
       "      <td>423.00</td>\n",
       "      <td>423.00</td>\n",
       "      <td>423.00</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:14:00</th>\n",
       "      <td>422.53</td>\n",
       "      <td>422.53</td>\n",
       "      <td>422.53</td>\n",
       "      <td>422.53</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:24:00</th>\n",
       "      <td>422.20</td>\n",
       "      <td>422.20</td>\n",
       "      <td>422.20</td>\n",
       "      <td>422.20</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:44:00</th>\n",
       "      <td>1449.99</td>\n",
       "      <td>1449.99</td>\n",
       "      <td>1449.99</td>\n",
       "      <td>1449.99</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:45:00</th>\n",
       "      <td>1449.05</td>\n",
       "      <td>1449.05</td>\n",
       "      <td>1449.05</td>\n",
       "      <td>1449.05</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:51:00</th>\n",
       "      <td>1451.00</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:56:00</th>\n",
       "      <td>1450.00</td>\n",
       "      <td>1450.00</td>\n",
       "      <td>1450.00</td>\n",
       "      <td>1450.00</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:59:00</th>\n",
       "      <td>1451.80</td>\n",
       "      <td>1451.80</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>1451.00</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "timestamp                                                      \n",
       "2020-01-02 04:03:00   422.07   422.50   422.07   422.50     928\n",
       "2020-01-02 04:04:00   422.16   422.16   422.16   422.16     356\n",
       "2020-01-02 04:07:00   423.00   423.00   423.00   423.00     201\n",
       "2020-01-02 04:14:00   422.53   422.53   422.53   422.53     160\n",
       "2020-01-02 04:24:00   422.20   422.20   422.20   422.20     196\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2020-08-07 19:44:00  1449.99  1449.99  1449.99  1449.99     413\n",
       "2020-08-07 19:45:00  1449.05  1449.05  1449.05  1449.05    1507\n",
       "2020-08-07 19:51:00  1451.00  1451.00  1451.00  1451.00     415\n",
       "2020-08-07 19:56:00  1450.00  1450.00  1450.00  1450.00     490\n",
       "2020-08-07 19:59:00  1451.80  1451.80  1451.00  1451.00     579\n",
       "\n",
       "[106732 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_history['TSLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSLAdata[‘close’].fillna(value=TSLAdata[‘Item_Weight’].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/750/0*XcQBOZQBItuoaFKi)\n",
    "\n",
    "Daily return of an asset is the ratio between the price variation over the initial price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/750/0*_SHk9qM3JOSGKeNE)\n",
    "\n",
    "The excess return over a certain period is the difference between the average return and the actual return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TSLA': -0.37056543719546275}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate returns and excess returns\n",
    "\n",
    "def add_all_returns():\n",
    "  for ticker in tickers:\n",
    "    hist = ticker_history[ticker]\n",
    "    hist['return'] = (hist['Close'] - hist['Open']) / hist['Open']\n",
    "    average = hist[\"return\"].mean()\n",
    "    average_returns[ticker] = average\n",
    "    cumulative_returns[ticker] = (hist[\"return\"] + 1).prod() - 1\n",
    "    hist['excess_return'] = hist['return'] - average\n",
    "    ticker_history[ticker] = hist\n",
    "\n",
    "add_all_returns()\n",
    "\n",
    "# display data\n",
    "cumulative_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things just happened here:\n",
    "\n",
    "We added the return and excess_return columns to every row of our historic data frames\n",
    "We stored the average return of every asset\n",
    "We stored the cumulative return for every historic we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to combine the excess returns into the n × k Excess Return Matrix X, where n is the number of observations (days, weeks, months, …) and k is the number of assets in out portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1000/0*pGapNlxAygWJdwQt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excess matrix\n",
    "\n",
    "excess_matrix = np.zeros((hist_length, len(tickers)))\n",
    "\n",
    "for i in range(0, hist_length):\n",
    "  for idx, ticker in enumerate(tickers):\n",
    "    excess_matrix[i][idx] = ticker_history[ticker].iloc[i]['excess_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excess matrix\n",
    "\n",
    "excess_matrix = np.zeros((hist_length, len(tickers)))\n",
    "\n",
    "for i in range(0, hist_length):\n",
    "  for idx, ticker in enumerate(tickers):\n",
    "    excess_matrix[i][idx] = ticker_history[ticker].iloc[i]['excess_return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line creates an n × k matrix and the loops assign the corresponding values to each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:03:00</th>\n",
       "      <td>0.001021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:04:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:07:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:14:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:24:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:44:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:45:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:51:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:56:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:59:00</th>\n",
       "      <td>-0.000549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106732 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         TSLA\n",
       "timestamp                    \n",
       "2020-01-02 04:03:00  0.001021\n",
       "2020-01-02 04:04:00  0.000002\n",
       "2020-01-02 04:07:00  0.000002\n",
       "2020-01-02 04:14:00  0.000002\n",
       "2020-01-02 04:24:00  0.000002\n",
       "...                       ...\n",
       "2020-08-07 19:44:00  0.000002\n",
       "2020-08-07 19:45:00  0.000002\n",
       "2020-08-07 19:51:00  0.000002\n",
       "2020-08-07 19:56:00  0.000002\n",
       "2020-08-07 19:59:00 -0.000549\n",
       "\n",
       "[106732 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(excess_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = ticker_history[tickers[0]].index\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*MKgTBXtRYApe1ycw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risk Modeling**\n",
    "\n",
    "There are many approaches that can be used to optimize a portfolio. In the present article we will analyze the variance and covariance of individual assets in order to minimize the global risk.\n",
    "\n",
    "To this end, we will use our Excess Return Matrix to compute the Variance-covariance Matrix Σ from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance co-variance matrix\n",
    "\n",
    "product_matrix = np.matmul(excess_matrix.transpose(), excess_matrix)\n",
    "var_covar_matrix = product_matrix / hist_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TSLA\n",
       "TSLA  0.000004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(var_covar_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*00nkyzYnQm3T28xN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cov x, y is the covariance between asset X and asset Y\n",
    "\n",
    "When x = y the value is the variance of the asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can jump into the actual portfolio optimization, our next target is the Correlation Matrix, where every item is defined like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/600/0*iPVjT37R1LW6FMZp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between assets X and Y is their covariance divided by the product of their standard deviations.\n",
    "\n",
    "We already have cov(X, Y) stored in var_covar_matrix so we need a k × k matrix with the products of each standard deviation.\n",
    "\n",
    "Let’s compute the individual standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation\n",
    "\n",
    "std_deviations = np.zeros((len(tickers), 1))\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "  std_deviations[idx][0] = np.std(ticker_history[ticker]['return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.002108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Std Dev\n",
       "TSLA  0.002108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(std_deviations).copy()\n",
    "pretty_matrix.columns = ['Std Dev']\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the matrix with the standard deviation products, we multiply the above by its transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std Deviation products matrix\n",
    "\n",
    "sdev_product_matrix = np.matmul(std_deviations, std_deviations.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TSLA\n",
       "TSLA  0.000004"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(sdev_product_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameError: name 'correlation_matrix' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-23-330ee9e23195>\u001b[0m(11)\u001b[0;36mminimize_volatility\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m  \u001b[0mticker_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# our variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m  \u001b[0mweighted_std_devs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_deviations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correlation_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-330ee9e23195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mticker_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize_volatility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mpretty_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Weight %\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-330ee9e23195>\u001b[0m in \u001b[0;36mminimize_volatility\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m      \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mticker_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# our variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mweighted_std_devs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_deviations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correlation_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimize weights to minimize variance\n",
    "\n",
    "def minimize_volatility():\n",
    "\n",
    "  # Define the model\n",
    "  # Portfolio Volatility = Sqrt (Transpose (Wt.SD) * Correlation Matrix * Wt. SD)\n",
    "    \n",
    "  if (DEBUGGING):\n",
    "     pdb.set_trace()\n",
    "\n",
    "  ticker_weights = tf.Variable(np.full((len(tickers), 1), 1.0 / len(tickers))) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "\n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "\n",
    "  # Run\n",
    "  learn_rate = 0.01\n",
    "  steps = 5000\n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Training using Gradient Descent to minimize variance\n",
    "  train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(portfolio_volatility)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(train_step)\n",
    "      if i % 1000 == 0 :\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        print(\"Weights\", ticker_weights.eval())\n",
    "        print(\"Volatility: {:.2f}%\".format(portfolio_volatility.eval() * 100))\n",
    "        print(\"\")\n",
    "        \n",
    "    return ticker_weights.eval()\n",
    "\n",
    "weights = minimize_volatility()\n",
    "\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we can finally compute the Correlation Matrix, as we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "\n",
    "correlation_matrix = var_covar_matrix / sdev_product_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TSLA\n",
       "TSLA   1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(correlation_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Correlation Matrix:\n",
    "\n",
    "The correlation of an asset’s returns with itself is always 1\n",
    "\n",
    "Correlation values range from –1 to 1\n",
    "\n",
    "Values tending to 1 mean that two random variables tend to have linear relationship\n",
    "\n",
    "Correlation values tending to –1 (anticorrelation) mean that two assets tend to have opposite behaviors\n",
    "\n",
    "Correlation values of 0 mean that two random variables are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Portfolio optimization**\n",
    "\n",
    "Given the average return and the variance of our assets, now it’s time to decide how much money is allocated in each one.\n",
    "\n",
    "At this point, we would like to find a combination of investments that minimizes the global variance of the portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/600/0*T-7HtN5qlYnlU1ay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights array is the output we aim to get from our portfolio optimizer. The weight of every asset can range from 0 to 1, and the overall sum must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the weights array, we can define the weighted standard deviation as:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*3hUQbQITXFV8ARY0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the global variance of our portfolio can now be defined as:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*liHv3gq7jchT_9BZ)\n",
    "\n",
    "Where W is a 1 × k matrix with the weighted standard deviations , C is the Correlation Matrix described above and the result is a 1 × 1 matrix with the global portfolio variance.\n",
    "\n",
    "This is the value that we want to minimize, but how can we do it? \n",
    "We could define functions that computed the global variance for given weight arrays, explore all the possible candidates and rate them.\n",
    "\n",
    "However, finding the absolute minimal value for an equation with k variables is an NP problem. The amount of calculations would grow exponentially with k if we attempted to evaluate every possible solution. Waiting 10³⁰ centuries to get an answer doesn’t look like an appealing scenario, does it?\n",
    "\n",
    "So the best alternative in our hands is to use Machine Learning to explore a diverse subset of the search space for us, and let it explore variants of branches with potential to perform better than their siblings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize weights using Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[round 0]\n",
      "Weights [[1.]]\n",
      "Volatility: 0.21%\n",
      "\n",
      "[round 2500]\n",
      "Weights [[1.]]\n",
      "Volatility: 0.21%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight %\n",
       "TSLA     100.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize weights to minimize variance\n",
    "\n",
    "def minimize_volatility():\n",
    "\n",
    "  # Define the model\n",
    "  # Portfolio Volatility = Sqrt (Transpose (Wt.SD) * Correlation Matrix * Wt. SD)\n",
    "\n",
    "  ticker_weights = tf.Variable(np.full((len(tickers), 1), 1.0 / len(tickers))) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "\n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "  # Constraints: sum([0..1, 0..1, ...]) = 1\n",
    "\n",
    "  lower_than_zero = tf.greater( np.float64(0), ticker_weights )\n",
    "  zero_minimum_op = ticker_weights.assign( tf.where (lower_than_zero, tf.zeros_like(ticker_weights), ticker_weights) )\n",
    "\n",
    "  greater_than_one = tf.greater( ticker_weights, np.float64(1) )\n",
    "  unity_max_op = ticker_weights.assign( tf.where (greater_than_one, tf.ones_like(ticker_weights), ticker_weights) )\n",
    "\n",
    "  result_sum = tf.reduce_sum(ticker_weights)\n",
    "  unity_sum_op = ticker_weights.assign(tf.divide(ticker_weights, result_sum))\n",
    "  \n",
    "  constraints_op = tf.group(zero_minimum_op, unity_max_op, unity_sum_op)\n",
    "\n",
    "  # Run\n",
    "  learning_rate = 0.01\n",
    "  steps = 5000\n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Training using Gradient Descent to minimize variance\n",
    "  optimize_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(portfolio_volatility)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(optimize_op)\n",
    "      sess.run(constraints_op)\n",
    "      if i % 2500 == 0 :\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        print(\"Weights\", ticker_weights.eval())\n",
    "        print(\"Volatility: {:.2f}%\".format(portfolio_volatility.eval() * 100))\n",
    "        print(\"\")\n",
    "        \n",
    "    sess.run(constraints_op)\n",
    "    return ticker_weights.eval()\n",
    "\n",
    "weights = minimize_volatility()\n",
    "\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[round 0]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 2000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 4000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 6000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 8000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "Took 22.327433s to complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight %\n",
       "TSLA     100.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize weights to maximize return/risk\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def maximize_sharpe_ratio():\n",
    "  \n",
    "  # Define the model\n",
    "  \n",
    "  # 1) Variance\n",
    "  \n",
    "  ticker_weights = tf.Variable(tf.random_uniform((len(tickers), 1), dtype=tf.float64)) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "  \n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "  \n",
    "  # 2) Return\n",
    "  \n",
    "  returns = np.full((len(tickers), 1), 0.0) # same as ticker_weights\n",
    "  for ticker_idx in range(0, len(tickers)):\n",
    "    returns[ticker_idx] = cumulative_returns[tickers[ticker_idx]]\n",
    "  \n",
    "  portfolio_return = tf.reduce_sum(tf.multiply(ticker_weights, returns))\n",
    "  \n",
    "  # 3) Return / Risk\n",
    "  \n",
    "  sharpe_ratio = tf.divide(portfolio_return, portfolio_volatility)\n",
    "  \n",
    "  # Constraints\n",
    "  \n",
    "  # all values positive, with unity sum\n",
    "  weights_sum = tf.reduce_sum(ticker_weights)\n",
    "  constraints_op = ticker_weights.assign(tf.divide(tf.abs(ticker_weights), tf.abs(weights_sum) ))\n",
    "  \n",
    "  # Run\n",
    "  learning_rate = 0.0001\n",
    "  learning_rate = 0.0015\n",
    "  steps = 10000\n",
    "  \n",
    "  # Training using Gradient Descent to minimize cost\n",
    "  \n",
    "  optimize_op = tf.train.GradientDescentOptimizer(learning_rate, use_locking=True).minimize(tf.negative(sharpe_ratio))\n",
    "  #2# optimize_op = tf.train.AdamOptimizer(learning_rate, use_locking=True).minimize(tf.negative(sharpe_ratio))\n",
    "  #3# optimize_op = tf.train.AdamOptimizer(learning_rate=0.00005, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False).minimize(tf.negative(sharpe_ratio))\n",
    "  #4# optimize_op = tf.train.AdagradOptimizer(learning_rate=0.01, initial_accumulator_value=0.1, use_locking=False).minimize(tf.negative(sharpe_ratio))\n",
    "  \n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    ratios = np.zeros(steps)\n",
    "    returns = np.zeros(steps)\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(optimize_op)\n",
    "      sess.run(constraints_op)\n",
    "      ratios[i] = sess.run(sharpe_ratio)\n",
    "      returns[i] = sess.run(portfolio_return) * 100\n",
    "      if i % 2000 == 0 : \n",
    "        sess.run(constraints_op)\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        #print(\"Ticker weights\", sess.run(ticker_weights))\n",
    "        print(\"Volatility {:.2f} %\".format(sess.run(portfolio_volatility)))\n",
    "        print(\"Return {:.2f} %\".format(sess.run(portfolio_return)*100))\n",
    "        print(\"Sharpe ratio\", sess.run(sharpe_ratio))\n",
    "        print(\"\")\n",
    "    \n",
    "    sess.run(constraints_op)\n",
    "    # print(\"Ticker weights\", sess.run(ticker_weights))\n",
    "    print(\"Volatility {:.2f} %\".format(sess.run(portfolio_volatility)))\n",
    "    print(\"Return {:.2f} %\".format(sess.run(portfolio_return)*100))\n",
    "    print(\"Sharpe ratio\", sess.run(sharpe_ratio))\n",
    "    return sess.run(ticker_weights)\n",
    "\n",
    "weights = maximize_sharpe_ratio()\n",
    "\n",
    "print(\"Took {:f}s to complete\".format(time.time() - start))\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def line_plot(line1, label1=None, units='', title=''):\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(line1, label=label1, linewidth=2)\n",
    "    ax.set_ylabel(units, fontsize=14)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "def lines_plot(line1, line2, label1=None, label2=None, units='', title=''):\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(line1, label=label1, linewidth=2)\n",
    "    ax.plot(line2, label=label2, linewidth=2)\n",
    "    ax.set_ylabel(units, fontsize=14)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
