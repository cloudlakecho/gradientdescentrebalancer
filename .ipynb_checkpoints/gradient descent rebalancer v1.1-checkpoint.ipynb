{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "TSLAdata=pd.read_csv(\"C:/Users/Andy/Downloads/TSLA/TSLA_2020_2020.txt\",delimiter=\"\\,\")\n",
    "TSLAdata.columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "#TSLAdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL\n",
    "\n",
    "tickers = [\"TSLA\"]\n",
    "mins_ago_to_fetch = 100000  # see also filter_history_by_date()\n",
    "ticker_history = {}\n",
    "hist_length = 0\n",
    "average_returns = {}\n",
    "cumulative_returns = {}\n",
    "\n",
    "def fetch_all():\n",
    "  for ticker in tickers:\n",
    "    ticker_history[ticker] = fetch_history(ticker)\n",
    "\n",
    "def fetch_history(ticker):\n",
    "  hist = pd.read_csv(\"C:/Users/Andy/Downloads/TSLA/TSLA_2020_2020.txt\",delimiter=\"\\,\")\n",
    "  hist.columns = [\"timestamp\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "  #hist = TSLAdata\n",
    "  hist = index_history(hist)\n",
    "  hist = filter_history_by_date(hist)\n",
    "  return hist\n",
    "\n",
    "def index_history(hist):\n",
    "  # index by date so we can easily filter by a given timeframe\n",
    "  hist = hist.set_index('timestamp')\n",
    "  hist.index = pd.to_datetime(hist.index, unit='ns')\n",
    "  return hist\n",
    "\n",
    "def filter_history_by_date(hist):\n",
    "  result = hist[hist.index.year >= 2016]\n",
    "  # result = result[result.index.day == 1] # every first of month, etc.\n",
    "  return result\n",
    "\n",
    "fetch_all()\n",
    "hist_length = len(ticker_history[tickers[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:03:00</th>\n",
       "      <td>422.0700</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>422.0700</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:04:00</th>\n",
       "      <td>422.1600</td>\n",
       "      <td>422.1600</td>\n",
       "      <td>422.1600</td>\n",
       "      <td>422.1600</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:07:00</th>\n",
       "      <td>423.0000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:14:00</th>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:24:00</th>\n",
       "      <td>422.2000</td>\n",
       "      <td>422.2000</td>\n",
       "      <td>422.2000</td>\n",
       "      <td>422.2000</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:29:00</th>\n",
       "      <td>422.3600</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>422.3600</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:43:00</th>\n",
       "      <td>422.4000</td>\n",
       "      <td>422.4000</td>\n",
       "      <td>422.4000</td>\n",
       "      <td>422.4000</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:46:00</th>\n",
       "      <td>422.1100</td>\n",
       "      <td>422.1100</td>\n",
       "      <td>422.1100</td>\n",
       "      <td>422.1100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:41:00</th>\n",
       "      <td>422.7100</td>\n",
       "      <td>422.7100</td>\n",
       "      <td>422.7100</td>\n",
       "      <td>422.7100</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:44:00</th>\n",
       "      <td>422.9900</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>422.9900</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:46:00</th>\n",
       "      <td>423.4600</td>\n",
       "      <td>423.4600</td>\n",
       "      <td>423.4600</td>\n",
       "      <td>423.4600</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:48:00</th>\n",
       "      <td>423.2100</td>\n",
       "      <td>423.2100</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:53:00</th>\n",
       "      <td>423.3600</td>\n",
       "      <td>423.3600</td>\n",
       "      <td>423.3600</td>\n",
       "      <td>423.3600</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:54:00</th>\n",
       "      <td>423.3600</td>\n",
       "      <td>423.3600</td>\n",
       "      <td>423.3500</td>\n",
       "      <td>423.3600</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:55:00</th>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:13:00</th>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>422.8600</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:20:00</th>\n",
       "      <td>422.5200</td>\n",
       "      <td>422.5200</td>\n",
       "      <td>422.5200</td>\n",
       "      <td>422.5200</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:37:00</th>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>422.5300</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:40:00</th>\n",
       "      <td>422.7900</td>\n",
       "      <td>422.7900</td>\n",
       "      <td>422.7900</td>\n",
       "      <td>422.7900</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:43:00</th>\n",
       "      <td>422.5500</td>\n",
       "      <td>422.5500</td>\n",
       "      <td>422.5500</td>\n",
       "      <td>422.5500</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:46:00</th>\n",
       "      <td>422.8500</td>\n",
       "      <td>422.8500</td>\n",
       "      <td>422.8500</td>\n",
       "      <td>422.8500</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:48:00</th>\n",
       "      <td>422.8500</td>\n",
       "      <td>423.2000</td>\n",
       "      <td>422.8500</td>\n",
       "      <td>423.2000</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:54:00</th>\n",
       "      <td>423.0100</td>\n",
       "      <td>423.0100</td>\n",
       "      <td>423.0100</td>\n",
       "      <td>423.0100</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:00:00</th>\n",
       "      <td>423.3000</td>\n",
       "      <td>423.8600</td>\n",
       "      <td>422.9000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:01:00</th>\n",
       "      <td>422.9000</td>\n",
       "      <td>423.2500</td>\n",
       "      <td>422.9000</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:02:00</th>\n",
       "      <td>422.9900</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>422.9900</td>\n",
       "      <td>423.0000</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:03:00</th>\n",
       "      <td>423.0100</td>\n",
       "      <td>423.0100</td>\n",
       "      <td>422.6400</td>\n",
       "      <td>422.6400</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:04:00</th>\n",
       "      <td>422.5000</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:05:00</th>\n",
       "      <td>422.3900</td>\n",
       "      <td>422.3900</td>\n",
       "      <td>422.3900</td>\n",
       "      <td>422.3900</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:06:00</th>\n",
       "      <td>422.5600</td>\n",
       "      <td>422.7000</td>\n",
       "      <td>422.3800</td>\n",
       "      <td>422.5000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:16:00</th>\n",
       "      <td>1453.0001</td>\n",
       "      <td>1453.0001</td>\n",
       "      <td>1453.0001</td>\n",
       "      <td>1453.0001</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:17:00</th>\n",
       "      <td>1452.4500</td>\n",
       "      <td>1452.7000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:18:00</th>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.2000</td>\n",
       "      <td>1448.0000</td>\n",
       "      <td>1448.0000</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:20:00</th>\n",
       "      <td>1449.1000</td>\n",
       "      <td>1449.1000</td>\n",
       "      <td>1449.0300</td>\n",
       "      <td>1449.0300</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:22:00</th>\n",
       "      <td>1449.3500</td>\n",
       "      <td>1449.3500</td>\n",
       "      <td>1449.0000</td>\n",
       "      <td>1449.0000</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:23:00</th>\n",
       "      <td>1447.0100</td>\n",
       "      <td>1447.0100</td>\n",
       "      <td>1447.0100</td>\n",
       "      <td>1447.0100</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:24:00</th>\n",
       "      <td>1448.0300</td>\n",
       "      <td>1448.0300</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:25:00</th>\n",
       "      <td>1447.7500</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:27:00</th>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:29:00</th>\n",
       "      <td>1449.5000</td>\n",
       "      <td>1449.5000</td>\n",
       "      <td>1449.5000</td>\n",
       "      <td>1449.5000</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:33:00</th>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:35:00</th>\n",
       "      <td>1446.3500</td>\n",
       "      <td>1446.5000</td>\n",
       "      <td>1446.3500</td>\n",
       "      <td>1446.5000</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:38:00</th>\n",
       "      <td>1445.0200</td>\n",
       "      <td>1446.0000</td>\n",
       "      <td>1445.0200</td>\n",
       "      <td>1446.0000</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:43:00</th>\n",
       "      <td>1447.1000</td>\n",
       "      <td>1447.1000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:55:00</th>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>1447.0000</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:16:00</th>\n",
       "      <td>1448.0000</td>\n",
       "      <td>1448.0000</td>\n",
       "      <td>1448.0000</td>\n",
       "      <td>1448.0000</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:20:00</th>\n",
       "      <td>1449.2000</td>\n",
       "      <td>1449.2000</td>\n",
       "      <td>1448.5500</td>\n",
       "      <td>1448.5500</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:23:00</th>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:33:00</th>\n",
       "      <td>1448.8300</td>\n",
       "      <td>1448.8300</td>\n",
       "      <td>1448.8300</td>\n",
       "      <td>1448.8300</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:39:00</th>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>1448.8200</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:41:00</th>\n",
       "      <td>1447.7700</td>\n",
       "      <td>1447.7700</td>\n",
       "      <td>1447.7700</td>\n",
       "      <td>1447.7700</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:59:00</th>\n",
       "      <td>1449.0000</td>\n",
       "      <td>1449.0000</td>\n",
       "      <td>1449.0000</td>\n",
       "      <td>1449.0000</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:05:00</th>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:19:00</th>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>1448.9900</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:41:00</th>\n",
       "      <td>1449.7000</td>\n",
       "      <td>1449.7000</td>\n",
       "      <td>1449.7000</td>\n",
       "      <td>1449.7000</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:44:00</th>\n",
       "      <td>1449.9900</td>\n",
       "      <td>1449.9900</td>\n",
       "      <td>1449.9900</td>\n",
       "      <td>1449.9900</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:45:00</th>\n",
       "      <td>1449.0500</td>\n",
       "      <td>1449.0500</td>\n",
       "      <td>1449.0500</td>\n",
       "      <td>1449.0500</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:51:00</th>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:56:00</th>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>1450.0000</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:59:00</th>\n",
       "      <td>1451.8000</td>\n",
       "      <td>1451.8000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>1451.0000</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Open       High        Low      Close  Volume\n",
       "timestamp                                                              \n",
       "2020-01-02 04:03:00   422.0700   422.5000   422.0700   422.5000     928\n",
       "2020-01-02 04:04:00   422.1600   422.1600   422.1600   422.1600     356\n",
       "2020-01-02 04:07:00   423.0000   423.0000   423.0000   423.0000     201\n",
       "2020-01-02 04:14:00   422.5300   422.5300   422.5300   422.5300     160\n",
       "2020-01-02 04:24:00   422.2000   422.2000   422.2000   422.2000     196\n",
       "2020-01-02 04:29:00   422.3600   422.5000   422.3600   422.5000     730\n",
       "2020-01-02 04:43:00   422.4000   422.4000   422.4000   422.4000     213\n",
       "2020-01-02 04:46:00   422.1100   422.1100   422.1100   422.1100     150\n",
       "2020-01-02 05:41:00   422.7100   422.7100   422.7100   422.7100     125\n",
       "2020-01-02 05:44:00   422.9900   423.0000   422.9900   423.0000     502\n",
       "2020-01-02 05:46:00   423.4600   423.4600   423.4600   423.4600     204\n",
       "2020-01-02 05:48:00   423.2100   423.2100   423.0000   423.0000     474\n",
       "2020-01-02 05:53:00   423.3600   423.3600   423.3600   423.3600     100\n",
       "2020-01-02 05:54:00   423.3600   423.3600   423.3500   423.3600     800\n",
       "2020-01-02 05:55:00   422.8600   422.8600   422.8600   422.8600     408\n",
       "2020-01-02 06:13:00   422.8600   422.8600   422.8600   422.8600     281\n",
       "2020-01-02 06:20:00   422.5200   422.5200   422.5200   422.5200     355\n",
       "2020-01-02 06:37:00   422.5300   422.5300   422.5300   422.5300     383\n",
       "2020-01-02 06:40:00   422.7900   422.7900   422.7900   422.7900     177\n",
       "2020-01-02 06:43:00   422.5500   422.5500   422.5500   422.5500     377\n",
       "2020-01-02 06:46:00   422.8500   422.8500   422.8500   422.8500     119\n",
       "2020-01-02 06:48:00   422.8500   423.2000   422.8500   423.2000     626\n",
       "2020-01-02 06:54:00   423.0100   423.0100   423.0100   423.0100     679\n",
       "2020-01-02 07:00:00   423.3000   423.8600   422.9000   423.0000    4729\n",
       "2020-01-02 07:01:00   422.9000   423.2500   422.9000   423.0000     622\n",
       "2020-01-02 07:02:00   422.9900   423.0000   422.9900   423.0000     472\n",
       "2020-01-02 07:03:00   423.0100   423.0100   422.6400   422.6400    1446\n",
       "2020-01-02 07:04:00   422.5000   422.5000   422.5000   422.5000    1905\n",
       "2020-01-02 07:05:00   422.3900   422.3900   422.3900   422.3900     509\n",
       "2020-01-02 07:06:00   422.5600   422.7000   422.3800   422.5000     999\n",
       "...                        ...        ...        ...        ...     ...\n",
       "2020-08-07 17:16:00  1453.0001  1453.0001  1453.0001  1453.0001     294\n",
       "2020-08-07 17:17:00  1452.4500  1452.7000  1451.0000  1451.0000    1354\n",
       "2020-08-07 17:18:00  1451.0000  1451.2000  1448.0000  1448.0000    3133\n",
       "2020-08-07 17:20:00  1449.1000  1449.1000  1449.0300  1449.0300     594\n",
       "2020-08-07 17:22:00  1449.3500  1449.3500  1449.0000  1449.0000     888\n",
       "2020-08-07 17:23:00  1447.0100  1447.0100  1447.0100  1447.0100     590\n",
       "2020-08-07 17:24:00  1448.0300  1448.0300  1447.0000  1447.0000     964\n",
       "2020-08-07 17:25:00  1447.7500  1448.9900  1447.0000  1447.0000    1994\n",
       "2020-08-07 17:27:00  1450.0000  1450.0000  1450.0000  1450.0000     825\n",
       "2020-08-07 17:29:00  1449.5000  1449.5000  1449.5000  1449.5000     191\n",
       "2020-08-07 17:33:00  1447.0000  1447.0000  1447.0000  1447.0000     880\n",
       "2020-08-07 17:35:00  1446.3500  1446.5000  1446.3500  1446.5000     873\n",
       "2020-08-07 17:38:00  1445.0200  1446.0000  1445.0200  1446.0000    1982\n",
       "2020-08-07 17:43:00  1447.1000  1447.1000  1447.0000  1447.0000     586\n",
       "2020-08-07 17:55:00  1447.0000  1447.0000  1447.0000  1447.0000     385\n",
       "2020-08-07 18:16:00  1448.0000  1448.0000  1448.0000  1448.0000     692\n",
       "2020-08-07 18:20:00  1449.2000  1449.2000  1448.5500  1448.5500     520\n",
       "2020-08-07 18:23:00  1448.8200  1448.8200  1448.8200  1448.8200     213\n",
       "2020-08-07 18:33:00  1448.8300  1448.8300  1448.8300  1448.8300     531\n",
       "2020-08-07 18:39:00  1448.8200  1448.8200  1448.8200  1448.8200     351\n",
       "2020-08-07 18:41:00  1447.7700  1447.7700  1447.7700  1447.7700     574\n",
       "2020-08-07 18:59:00  1449.0000  1449.0000  1449.0000  1449.0000     354\n",
       "2020-08-07 19:05:00  1448.9900  1448.9900  1448.9900  1448.9900     286\n",
       "2020-08-07 19:19:00  1448.9900  1448.9900  1448.9900  1448.9900     309\n",
       "2020-08-07 19:41:00  1449.7000  1449.7000  1449.7000  1449.7000     151\n",
       "2020-08-07 19:44:00  1449.9900  1449.9900  1449.9900  1449.9900     413\n",
       "2020-08-07 19:45:00  1449.0500  1449.0500  1449.0500  1449.0500    1507\n",
       "2020-08-07 19:51:00  1451.0000  1451.0000  1451.0000  1451.0000     415\n",
       "2020-08-07 19:56:00  1450.0000  1450.0000  1450.0000  1450.0000     490\n",
       "2020-08-07 19:59:00  1451.8000  1451.8000  1451.0000  1451.0000     579\n",
       "\n",
       "[106732 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_history['TSLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSLAdata[‘close’].fillna(value=TSLAdata[‘Item_Weight’].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/750/0*XcQBOZQBItuoaFKi)\n",
    "\n",
    "Daily return of an asset is the ratio between the price variation over the initial price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/750/0*_SHk9qM3JOSGKeNE)\n",
    "\n",
    "The excess return over a certain period is the difference between the average return and the actual return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TSLA': -0.37056543719546275}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate returns and excess returns\n",
    "\n",
    "def add_all_returns():\n",
    "  for ticker in tickers:\n",
    "    hist = ticker_history[ticker]\n",
    "    hist['return'] = (hist['Close'] - hist['Open']) / hist['Open']\n",
    "    average = hist[\"return\"].mean()\n",
    "    average_returns[ticker] = average\n",
    "    cumulative_returns[ticker] = (hist[\"return\"] + 1).prod() - 1\n",
    "    hist['excess_return'] = hist['return'] - average\n",
    "    ticker_history[ticker] = hist\n",
    "\n",
    "add_all_returns()\n",
    "\n",
    "# display data\n",
    "cumulative_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things just happened here:\n",
    "\n",
    "We added the return and excess_return columns to every row of our historic data frames\n",
    "We stored the average return of every asset\n",
    "We stored the cumulative return for every historic we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to combine the excess returns into the n × k Excess Return Matrix X, where n is the number of observations (days, weeks, months, …) and k is the number of assets in out portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1000/0*pGapNlxAygWJdwQt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excess matrix\n",
    "\n",
    "excess_matrix = np.zeros((hist_length, len(tickers)))\n",
    "\n",
    "for i in range(0, hist_length):\n",
    "  for idx, ticker in enumerate(tickers):\n",
    "    excess_matrix[i][idx] = ticker_history[ticker].iloc[i]['excess_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excess matrix\n",
    "\n",
    "excess_matrix = np.zeros((hist_length, len(tickers)))\n",
    "\n",
    "for i in range(0, hist_length):\n",
    "  for idx, ticker in enumerate(tickers):\n",
    "    excess_matrix[i][idx] = ticker_history[ticker].iloc[i]['excess_return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line creates an n × k matrix and the loops assign the corresponding values to each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:03:00</th>\n",
       "      <td>0.001021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:04:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:07:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:14:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:24:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:29:00</th>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:43:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:46:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:41:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:44:00</th>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:46:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:48:00</th>\n",
       "      <td>-0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:53:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:54:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:55:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:13:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:20:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:37:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:40:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:43:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:46:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:48:00</th>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 06:54:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:00:00</th>\n",
       "      <td>-0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:01:00</th>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:02:00</th>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:03:00</th>\n",
       "      <td>-0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:04:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:05:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 07:06:00</th>\n",
       "      <td>-0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:16:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:17:00</th>\n",
       "      <td>-0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:18:00</th>\n",
       "      <td>-0.002065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:20:00</th>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:22:00</th>\n",
       "      <td>-0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:23:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:24:00</th>\n",
       "      <td>-0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:25:00</th>\n",
       "      <td>-0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:27:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:29:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:33:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:35:00</th>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:38:00</th>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:43:00</th>\n",
       "      <td>-0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 17:55:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:16:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:20:00</th>\n",
       "      <td>-0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:23:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:33:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:39:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:41:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 18:59:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:05:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:19:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:41:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:44:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:45:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:51:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:56:00</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07 19:59:00</th>\n",
       "      <td>-0.000549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106732 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         TSLA\n",
       "timestamp                    \n",
       "2020-01-02 04:03:00  0.001021\n",
       "2020-01-02 04:04:00  0.000002\n",
       "2020-01-02 04:07:00  0.000002\n",
       "2020-01-02 04:14:00  0.000002\n",
       "2020-01-02 04:24:00  0.000002\n",
       "2020-01-02 04:29:00  0.000334\n",
       "2020-01-02 04:43:00  0.000002\n",
       "2020-01-02 04:46:00  0.000002\n",
       "2020-01-02 05:41:00  0.000002\n",
       "2020-01-02 05:44:00  0.000026\n",
       "2020-01-02 05:46:00  0.000002\n",
       "2020-01-02 05:48:00 -0.000494\n",
       "2020-01-02 05:53:00  0.000002\n",
       "2020-01-02 05:54:00  0.000002\n",
       "2020-01-02 05:55:00  0.000002\n",
       "2020-01-02 06:13:00  0.000002\n",
       "2020-01-02 06:20:00  0.000002\n",
       "2020-01-02 06:37:00  0.000002\n",
       "2020-01-02 06:40:00  0.000002\n",
       "2020-01-02 06:43:00  0.000002\n",
       "2020-01-02 06:46:00  0.000002\n",
       "2020-01-02 06:48:00  0.000830\n",
       "2020-01-02 06:54:00  0.000002\n",
       "2020-01-02 07:00:00 -0.000707\n",
       "2020-01-02 07:01:00  0.000239\n",
       "2020-01-02 07:02:00  0.000026\n",
       "2020-01-02 07:03:00 -0.000873\n",
       "2020-01-02 07:04:00  0.000002\n",
       "2020-01-02 07:05:00  0.000002\n",
       "2020-01-02 07:06:00 -0.000140\n",
       "...                       ...\n",
       "2020-08-07 17:16:00  0.000002\n",
       "2020-08-07 17:17:00 -0.000996\n",
       "2020-08-07 17:18:00 -0.002065\n",
       "2020-08-07 17:20:00 -0.000046\n",
       "2020-08-07 17:22:00 -0.000239\n",
       "2020-08-07 17:23:00  0.000002\n",
       "2020-08-07 17:24:00 -0.000709\n",
       "2020-08-07 17:25:00 -0.000516\n",
       "2020-08-07 17:27:00  0.000002\n",
       "2020-08-07 17:29:00  0.000002\n",
       "2020-08-07 17:33:00  0.000002\n",
       "2020-08-07 17:35:00  0.000106\n",
       "2020-08-07 17:38:00  0.000680\n",
       "2020-08-07 17:43:00 -0.000067\n",
       "2020-08-07 17:55:00  0.000002\n",
       "2020-08-07 18:16:00  0.000002\n",
       "2020-08-07 18:20:00 -0.000446\n",
       "2020-08-07 18:23:00  0.000002\n",
       "2020-08-07 18:33:00  0.000002\n",
       "2020-08-07 18:39:00  0.000002\n",
       "2020-08-07 18:41:00  0.000002\n",
       "2020-08-07 18:59:00  0.000002\n",
       "2020-08-07 19:05:00  0.000002\n",
       "2020-08-07 19:19:00  0.000002\n",
       "2020-08-07 19:41:00  0.000002\n",
       "2020-08-07 19:44:00  0.000002\n",
       "2020-08-07 19:45:00  0.000002\n",
       "2020-08-07 19:51:00  0.000002\n",
       "2020-08-07 19:56:00  0.000002\n",
       "2020-08-07 19:59:00 -0.000549\n",
       "\n",
       "[106732 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(excess_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = ticker_history[tickers[0]].index\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*MKgTBXtRYApe1ycw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risk Modeling**\n",
    "\n",
    "There are many approaches that can be used to optimize a portfolio. In the present article we will analyze the variance and covariance of individual assets in order to minimize the global risk.\n",
    "\n",
    "To this end, we will use our Excess Return Matrix to compute the Variance-covariance Matrix Σ from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance co-variance matrix\n",
    "\n",
    "product_matrix = np.matmul(excess_matrix.transpose(), excess_matrix)\n",
    "var_covar_matrix = product_matrix / hist_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TSLA\n",
       "TSLA  0.000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(var_covar_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*00nkyzYnQm3T28xN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cov x, y is the covariance between asset X and asset Y\n",
    "\n",
    "When x = y the value is the variance of the asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can jump into the actual portfolio optimization, our next target is the Correlation Matrix, where every item is defined like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/600/0*iPVjT37R1LW6FMZp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between assets X and Y is their covariance divided by the product of their standard deviations.\n",
    "\n",
    "We already have cov(X, Y) stored in var_covar_matrix so we need a k × k matrix with the products of each standard deviation.\n",
    "\n",
    "Let’s compute the individual standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation\n",
    "\n",
    "std_deviations = np.zeros((len(tickers), 1))\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "  std_deviations[idx][0] = np.std(ticker_history[ticker]['return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.002108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Std Dev\n",
       "TSLA  0.002108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(std_deviations).copy()\n",
    "pretty_matrix.columns = ['Std Dev']\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the matrix with the standard deviation products, we multiply the above by its transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std Deviation products matrix\n",
    "\n",
    "sdev_product_matrix = np.matmul(std_deviations, std_deviations.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TSLA\n",
       "TSLA  0.000004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(sdev_product_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we can finally compute the Correlation Matrix, as we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "\n",
    "correlation_matrix = var_covar_matrix / sdev_product_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TSLA\n",
       "TSLA   1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_matrix = pd.DataFrame(correlation_matrix).copy()\n",
    "pretty_matrix.columns = tickers\n",
    "pretty_matrix.index = tickers\n",
    "\n",
    "pretty_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Correlation Matrix:\n",
    "\n",
    "The correlation of an asset’s returns with itself is always 1\n",
    "\n",
    "Correlation values range from –1 to 1\n",
    "\n",
    "Values tending to 1 mean that two random variables tend to have linear relationship\n",
    "\n",
    "Correlation values tending to –1 (anticorrelation) mean that two assets tend to have opposite behaviors\n",
    "\n",
    "Correlation values of 0 mean that two random variables are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Portfolio optimization**\n",
    "\n",
    "Given the average return and the variance of our assets, now it’s time to decide how much money is allocated in each one.\n",
    "\n",
    "At this point, we would like to find a combination of investments that minimizes the global variance of the portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/600/0*T-7HtN5qlYnlU1ay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights array is the output we aim to get from our portfolio optimizer. The weight of every asset can range from 0 to 1, and the overall sum must be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the weights array, we can define the weighted standard deviation as:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*3hUQbQITXFV8ARY0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the global variance of our portfolio can now be defined as:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*liHv3gq7jchT_9BZ)\n",
    "\n",
    "Where W is a 1 × k matrix with the weighted standard deviations , C is the Correlation Matrix described above and the result is a 1 × 1 matrix with the global portfolio variance.\n",
    "\n",
    "This is the value that we want to minimize, but how can we do it? \n",
    "We could define functions that computed the global variance for given weight arrays, explore all the possible candidates and rate them.\n",
    "\n",
    "However, finding the absolute minimal value for an equation with k variables is an NP problem. The amount of calculations would grow exponentially with k if we attempted to evaluate every possible solution. Waiting 10³⁰ centuries to get an answer doesn’t look like an appealing scenario, does it?\n",
    "\n",
    "So the best alternative in our hands is to use Machine Learning to explore a diverse subset of the search space for us, and let it explore variants of branches with potential to perform better than their siblings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize weights using Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[round 0]\n",
      "Weights [[0.99997892]]\n",
      "Volatility: 0.21%\n",
      "\n",
      "[round 1000]\n",
      "Weights [[0.97889679]]\n",
      "Volatility: 0.21%\n",
      "\n",
      "[round 2000]\n",
      "Weights [[0.95781466]]\n",
      "Volatility: 0.20%\n",
      "\n",
      "[round 3000]\n",
      "Weights [[0.93673253]]\n",
      "Volatility: 0.20%\n",
      "\n",
      "[round 4000]\n",
      "Weights [[0.9156504]]\n",
      "Volatility: 0.19%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>89.458936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Weight %\n",
       "TSLA  89.458936"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize weights to minimize variance\n",
    "\n",
    "def minimize_volatility():\n",
    "\n",
    "  # Define the model\n",
    "  # Portfolio Volatility = Sqrt (Transpose (Wt.SD) * Correlation Matrix * Wt. SD)\n",
    "\n",
    "  ticker_weights = tf.Variable(np.full((len(tickers), 1), 1.0 / len(tickers))) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "\n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "\n",
    "  # Run\n",
    "  learn_rate = 0.01\n",
    "  steps = 5000\n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Training using Gradient Descent to minimize variance\n",
    "  train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(portfolio_volatility)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(train_step)\n",
    "      if i % 1000 == 0 :\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        print(\"Weights\", ticker_weights.eval())\n",
    "        print(\"Volatility: {:.2f}%\".format(portfolio_volatility.eval() * 100))\n",
    "        print(\"\")\n",
    "        \n",
    "    return ticker_weights.eval()\n",
    "\n",
    "weights = minimize_volatility()\n",
    "\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[round 0]\n",
      "Weights [[1.]]\n",
      "Volatility: 0.21%\n",
      "\n",
      "[round 2500]\n",
      "Weights [[1.]]\n",
      "Volatility: 0.21%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight %\n",
       "TSLA     100.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize weights to minimize variance\n",
    "\n",
    "def minimize_volatility():\n",
    "\n",
    "  # Define the model\n",
    "  # Portfolio Volatility = Sqrt (Transpose (Wt.SD) * Correlation Matrix * Wt. SD)\n",
    "\n",
    "  ticker_weights = tf.Variable(np.full((len(tickers), 1), 1.0 / len(tickers))) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "\n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "  # Constraints: sum([0..1, 0..1, ...]) = 1\n",
    "\n",
    "  lower_than_zero = tf.greater( np.float64(0), ticker_weights )\n",
    "  zero_minimum_op = ticker_weights.assign( tf.where (lower_than_zero, tf.zeros_like(ticker_weights), ticker_weights) )\n",
    "\n",
    "  greater_than_one = tf.greater( ticker_weights, np.float64(1) )\n",
    "  unity_max_op = ticker_weights.assign( tf.where (greater_than_one, tf.ones_like(ticker_weights), ticker_weights) )\n",
    "\n",
    "  result_sum = tf.reduce_sum(ticker_weights)\n",
    "  unity_sum_op = ticker_weights.assign(tf.divide(ticker_weights, result_sum))\n",
    "  \n",
    "  constraints_op = tf.group(zero_minimum_op, unity_max_op, unity_sum_op)\n",
    "\n",
    "  # Run\n",
    "  learning_rate = 0.01\n",
    "  steps = 5000\n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  # Training using Gradient Descent to minimize variance\n",
    "  optimize_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(portfolio_volatility)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(optimize_op)\n",
    "      sess.run(constraints_op)\n",
    "      if i % 2500 == 0 :\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        print(\"Weights\", ticker_weights.eval())\n",
    "        print(\"Volatility: {:.2f}%\".format(portfolio_volatility.eval() * 100))\n",
    "        print(\"\")\n",
    "        \n",
    "    sess.run(constraints_op)\n",
    "    return ticker_weights.eval()\n",
    "\n",
    "weights = minimize_volatility()\n",
    "\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[round 0]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 2000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 4000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 6000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "[round 8000]\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "\n",
      "Volatility 0.00 %\n",
      "Return -37.06 %\n",
      "Sharpe ratio -175.77229960557872\n",
      "Took 22.327433s to complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight %\n",
       "TSLA     100.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize weights to maximize return/risk\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def maximize_sharpe_ratio():\n",
    "  \n",
    "  # Define the model\n",
    "  \n",
    "  # 1) Variance\n",
    "  \n",
    "  ticker_weights = tf.Variable(tf.random_uniform((len(tickers), 1), dtype=tf.float64)) # our variables\n",
    "  weighted_std_devs = tf.multiply(ticker_weights, std_deviations)\n",
    "  \n",
    "  product_1 = tf.transpose(weighted_std_devs)\n",
    "  product_2 = tf.matmul(product_1, correlation_matrix)\n",
    "  \n",
    "  portfolio_variance = tf.matmul(product_2, weighted_std_devs)\n",
    "  portfolio_volatility = tf.sqrt(tf.reduce_sum(portfolio_variance))\n",
    "\n",
    "  \n",
    "  # 2) Return\n",
    "  \n",
    "  returns = np.full((len(tickers), 1), 0.0) # same as ticker_weights\n",
    "  for ticker_idx in range(0, len(tickers)):\n",
    "    returns[ticker_idx] = cumulative_returns[tickers[ticker_idx]]\n",
    "  \n",
    "  portfolio_return = tf.reduce_sum(tf.multiply(ticker_weights, returns))\n",
    "  \n",
    "  # 3) Return / Risk\n",
    "  \n",
    "  sharpe_ratio = tf.divide(portfolio_return, portfolio_volatility)\n",
    "  \n",
    "  # Constraints\n",
    "  \n",
    "  # all values positive, with unity sum\n",
    "  weights_sum = tf.reduce_sum(ticker_weights)\n",
    "  constraints_op = ticker_weights.assign(tf.divide(tf.abs(ticker_weights), tf.abs(weights_sum) ))\n",
    "  \n",
    "  # Run\n",
    "  learning_rate = 0.0001\n",
    "  learning_rate = 0.0015\n",
    "  steps = 10000\n",
    "  \n",
    "  # Training using Gradient Descent to minimize cost\n",
    "  \n",
    "  optimize_op = tf.train.GradientDescentOptimizer(learning_rate, use_locking=True).minimize(tf.negative(sharpe_ratio))\n",
    "  #2# optimize_op = tf.train.AdamOptimizer(learning_rate, use_locking=True).minimize(tf.negative(sharpe_ratio))\n",
    "  #3# optimize_op = tf.train.AdamOptimizer(learning_rate=0.00005, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False).minimize(tf.negative(sharpe_ratio))\n",
    "  #4# optimize_op = tf.train.AdagradOptimizer(learning_rate=0.01, initial_accumulator_value=0.1, use_locking=False).minimize(tf.negative(sharpe_ratio))\n",
    "  \n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    ratios = np.zeros(steps)\n",
    "    returns = np.zeros(steps)\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "      sess.run(optimize_op)\n",
    "      sess.run(constraints_op)\n",
    "      ratios[i] = sess.run(sharpe_ratio)\n",
    "      returns[i] = sess.run(portfolio_return) * 100\n",
    "      if i % 2000 == 0 : \n",
    "        sess.run(constraints_op)\n",
    "        print(\"[round {:d}]\".format(i))\n",
    "        #print(\"Ticker weights\", sess.run(ticker_weights))\n",
    "        print(\"Volatility {:.2f} %\".format(sess.run(portfolio_volatility)))\n",
    "        print(\"Return {:.2f} %\".format(sess.run(portfolio_return)*100))\n",
    "        print(\"Sharpe ratio\", sess.run(sharpe_ratio))\n",
    "        print(\"\")\n",
    "    \n",
    "    sess.run(constraints_op)\n",
    "    # print(\"Ticker weights\", sess.run(ticker_weights))\n",
    "    print(\"Volatility {:.2f} %\".format(sess.run(portfolio_volatility)))\n",
    "    print(\"Return {:.2f} %\".format(sess.run(portfolio_return)*100))\n",
    "    print(\"Sharpe ratio\", sess.run(sharpe_ratio))\n",
    "    return sess.run(ticker_weights)\n",
    "\n",
    "weights = maximize_sharpe_ratio()\n",
    "\n",
    "print(\"Took {:f}s to complete\".format(time.time() - start))\n",
    "pretty_weights = pd.DataFrame(weights * 100, index = tickers, columns = [\"Weight %\"])\n",
    "\n",
    "pretty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def line_plot(line1, label1=None, units='', title=''):\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(line1, label=label1, linewidth=2)\n",
    "    ax.set_ylabel(units, fontsize=14)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "def lines_plot(line1, line2, label1=None, label2=None, units='', title=''):\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    ax.plot(line1, label=label1, linewidth=2)\n",
    "    ax.plot(line2, label=label2, linewidth=2)\n",
    "    ax.set_ylabel(units, fontsize=14)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.legend(loc='best', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
